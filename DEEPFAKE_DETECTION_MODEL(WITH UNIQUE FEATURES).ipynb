{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b173335-eace-49e8-81f0-743fc08c99c8",
   "metadata": {},
   "source": [
    "## MODEL- FEATURE1 - IMAGE UPLOAD FROM GALLERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7dc2d5c-453f-4d06-8632-70805af13ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepfake Probability: 0.5212\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load Pretrained Xception Model\n",
    "class DeepfakeDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepfakeDetector, self).__init__()\n",
    "        self.model = timm.create_model('xception', pretrained=True)  # Load Xception\n",
    "        self.model.fc = nn.Linear(self.model.num_features, 1)  # Modify output for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid for probability score\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.model(x))\n",
    "\n",
    "# Load Model\n",
    "model = DeepfakeDetector()\n",
    "model.eval()\n",
    "\n",
    "# Define Image Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Required for Xception\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalization\n",
    "])\n",
    "\n",
    "def predict_deepfake(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Load Image\n",
    "    image = transform(image).unsqueeze(0)  # Apply Transformations\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        probability = output.item()\n",
    "    \n",
    "    return probability  # Probability of being a deepfake\n",
    "\n",
    "# Example Usage\n",
    "image_path = \"th (1).jpeg\"  # Provide an image path\n",
    "score = predict_deepfake(image_path)\n",
    "print(f\"Deepfake Probability: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940e50bc-8cc6-453e-b6e5-376db9e1e7da",
   "metadata": {},
   "source": [
    "### FEATURE 2 - VIDEO UPLOAD WITH LIVE PROBABLITY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe74f31-8289-4c16-a938-cad3edb44e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 21 frames from WhatsApp Video 2025-02-27 at 11.44.35_3f0b0dfd.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_folder, frame_rate=1):\n",
    "    \"\"\"\n",
    "    Extracts frames from a video at a given frame rate.\n",
    "    :param video_path: Path to the input video file\n",
    "    :param output_folder: Folder to save extracted frames\n",
    "    :param frame_rate: Extract 1 frame per 'frame_rate' seconds\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Create output folder\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)  # Load Video\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))  # Get frames per second\n",
    "    frame_interval = fps * frame_rate  # Set frame extraction interval\n",
    "    \n",
    "    count = 0\n",
    "    frame_id = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()  # Read Frame\n",
    "        if not ret:\n",
    "            break  # Stop if video ends\n",
    "        \n",
    "        if count % frame_interval == 0:\n",
    "            frame_filename = f\"{output_folder}/frame_{frame_id}.jpg\"\n",
    "            cv2.imwrite(frame_filename, frame)  # Save frame as an image\n",
    "            frame_id += 1\n",
    "        \n",
    "        count += 1  # Update frame counter\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Extracted {frame_id} frames from {video_path}\")\n",
    "\n",
    "# Example Usage\n",
    "video_path = \"WhatsApp Video 2025-02-27 at 11.44.35_3f0b0dfd.mp4\"  # Provide a video path\n",
    "output_folder = \"frames\"\n",
    "extract_frames(video_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec629bb4-cbfc-4336-93a7-0d01950a559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 21 frames from WhatsApp Video 2025-02-27 at 11.44.35_3f0b0dfd.mp4\n",
      "frames\\frame_0.jpg: Deepfake Probability = 0.4893\n",
      "frames\\frame_1.jpg: Deepfake Probability = 0.5387\n",
      "frames\\frame_10.jpg: Deepfake Probability = 0.4929\n",
      "frames\\frame_11.jpg: Deepfake Probability = 0.5172\n",
      "frames\\frame_12.jpg: Deepfake Probability = 0.4999\n",
      "frames\\frame_13.jpg: Deepfake Probability = 0.5006\n",
      "frames\\frame_14.jpg: Deepfake Probability = 0.5196\n",
      "frames\\frame_15.jpg: Deepfake Probability = 0.5103\n",
      "frames\\frame_16.jpg: Deepfake Probability = 0.5134\n",
      "frames\\frame_17.jpg: Deepfake Probability = 0.5318\n",
      "frames\\frame_18.jpg: Deepfake Probability = 0.5306\n",
      "frames\\frame_19.jpg: Deepfake Probability = 0.5291\n",
      "frames\\frame_2.jpg: Deepfake Probability = 0.5342\n",
      "frames\\frame_20.jpg: Deepfake Probability = 0.5344\n",
      "frames\\frame_3.jpg: Deepfake Probability = 0.5301\n",
      "frames\\frame_4.jpg: Deepfake Probability = 0.5154\n",
      "frames\\frame_5.jpg: Deepfake Probability = 0.5098\n",
      "frames\\frame_6.jpg: Deepfake Probability = 0.5004\n",
      "frames\\frame_7.jpg: Deepfake Probability = 0.5009\n",
      "frames\\frame_8.jpg: Deepfake Probability = 0.5059\n",
      "frames\\frame_9.jpg: Deepfake Probability = 0.5432\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def detect_deepfake_in_video(video_path, output_folder):\n",
    "    \"\"\"\n",
    "    Extracts frames and detects deepfakes in a video.\n",
    "    :param video_path: Path to video file\n",
    "    :param output_folder: Folder to save frames and results\n",
    "    \"\"\"\n",
    "    extract_frames(video_path, output_folder)  # Extract frames\n",
    "\n",
    "    results = {}  # Store frame results\n",
    "\n",
    "    for frame in sorted(glob.glob(f\"{output_folder}/*.jpg\")):\n",
    "        probability = predict_deepfake(frame)  # Predict deepfake score\n",
    "        results[frame] = probability\n",
    "        print(f\"{frame}: Deepfake Probability = {probability:.4f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example Usage\n",
    "video_results = detect_deepfake_in_video(\"WhatsApp Video 2025-02-27 at 11.44.35_3f0b0dfd.mp4\", \"frames\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3494b-ca89-40ce-b420-a7cfd53472fb",
   "metadata": {},
   "source": [
    "### FEATURE 3 -- LIVE WEBCAM DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b3b1bf-0d64-45e7-ad88-0b43a0482a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "# Load OpenCV's pre-trained face detector (Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_fake(frame, prev_frame):\n",
    "    \"\"\" \n",
    "    Detects movement by comparing the current frame with the previous one.\n",
    "    Returns a fake probability (0-100%).\n",
    "    \"\"\"\n",
    "    if prev_frame is None:\n",
    "        return 0  # No previous frame to compare\n",
    "    \n",
    "    diff = cv2.absdiff(frame, prev_frame)\n",
    "    score = np.mean(diff)  # Calculate difference score\n",
    "\n",
    "    probability = min(int(score / 2), 100)  # Scale to 0-100%\n",
    "    return probability\n",
    "\n",
    "def open_webcam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    prev_frame = None  # Store previous frame\n",
    "\n",
    "    def update_frame():\n",
    "        nonlocal prev_frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        # Convert frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "        # Convert frame to RGB (for displaying in Tkinter)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Compute deepfake probability\n",
    "        probability = detect_fake(frame, prev_frame)\n",
    "        prev_frame = frame.copy()  # Store frame for next comparison\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Determine border color: Red (Fake) or Green (Real)\n",
    "            color = (255, 0, 0) if probability > 50 else (0, 255, 0)\n",
    "\n",
    "            # Draw a colored rectangle around the detected face\n",
    "            cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 3)\n",
    "\n",
    "            # Display probability percentage on the frame\n",
    "            text = f\"{probability}%\"\n",
    "            cv2.putText(frame_rgb, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        # Convert frame to Tkinter format\n",
    "        img = Image.fromarray(frame_rgb)\n",
    "        img_tk = ImageTk.PhotoImage(image=img)\n",
    "\n",
    "        label.img_tk = img_tk\n",
    "        label.config(image=img_tk)\n",
    "\n",
    "        # Update label text\n",
    "        status_text = f\"Deepfake Probability: {probability}%\"\n",
    "        label_status.config(text=status_text, fg=\"red\" if probability > 50 else \"green\")\n",
    "\n",
    "        root.after(10, update_frame)  # Refresh every 10ms\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Live Deepfake Detection\")\n",
    "\n",
    "    label = tk.Label(root)\n",
    "    label.pack()\n",
    "\n",
    "    label_status = tk.Label(root, text=\"\", font=(\"Arial\", 16, \"bold\"))\n",
    "    label_status.pack()\n",
    "\n",
    "    update_frame()  # Start webcam stream\n",
    "\n",
    "    root.mainloop()\n",
    "    cap.release()\n",
    "\n",
    "# Run the function\n",
    "open_webcam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1791cf-5ace-428f-a393-bb51453fabd3",
   "metadata": {},
   "source": [
    "## FEATURE 4 -- CLASSIFICATION REPORT DOWNLOADED AS PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e3c1dc0-1148-4e30-b0bb-78bfbe2d2342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image saved as th (1).jpeg\n",
      "Report saved as deepfake_report.pdf\n",
      "Report saved as deepfake_report.pdf\n",
      "Processed video saved as WhatsApp Video 2025-02-27 at 11.44.35_3f0b0dfd.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "from fpdf import FPDF\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Load OpenCV's pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_fake(frame, prev_frame):\n",
    "    \"\"\"\n",
    "    Detects movement by comparing the current frame with the previous one.\n",
    "    Returns a fake probability (0-100%).\n",
    "    \"\"\"\n",
    "    if prev_frame is None:\n",
    "        return 0  # No previous frame to compare\n",
    "    \n",
    "    diff = cv2.absdiff(frame, prev_frame)\n",
    "    score = np.mean(diff)  # Calculate difference score\n",
    "\n",
    "    probability = min(int(score / 2), 100)  # Scale to 0-100%\n",
    "    return probability\n",
    "\n",
    "def process_frame(frame, prev_frame):\n",
    "    \"\"\" Detects faces, applies colored borders, and returns processed frame with probability. \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    # Convert frame to RGB for display\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Compute deepfake probability\n",
    "    probability = detect_fake(frame, prev_frame)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Choose color: Red (Fake) or Green (Real)\n",
    "        color = (255, 0, 0) if probability > 50 else (0, 255, 0)\n",
    "\n",
    "        # Draw rectangle around face\n",
    "        cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 3)\n",
    "\n",
    "        # Display probability percentage\n",
    "        text = f\"{probability}%\"\n",
    "        cv2.putText(frame_rgb, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "    return frame_rgb, probability\n",
    "\n",
    "def process_image():\n",
    "    \"\"\" Processes an image for deepfake detection. \"\"\"\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "    if not file_path:\n",
    "        return\n",
    "    \n",
    "    frame = cv2.imread(file_path)\n",
    "    if frame is None:\n",
    "        print(\"Error: Could not read the image file!\")\n",
    "        return\n",
    "    \n",
    "    processed_frame, probability = process_frame(frame, None)\n",
    "    \n",
    "    # Save processed image\n",
    "    output_path = \"th (1).jpeg\"\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Processed image saved as {output_path}\")\n",
    "    \n",
    "    generate_pdf(file_path, probability)  # Generate PDF Report\n",
    "    \n",
    "    # Display image\n",
    "    cv2.imshow(\"Processed Image\", processed_frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def process_video():\n",
    "    \"\"\" Processes a video file for deepfake detection. \"\"\"\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Video Files\", \"*.mp4;*.avi\")])\n",
    "    if not file_path:\n",
    "        return\n",
    "    \n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    prev_frame = None\n",
    "    \n",
    "    # Video properties\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    output_path = \"WhatsApp Video 2025-02-27 at 11.44.35_3f0b0dfd.mp4\"\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    total_probability = 0\n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        processed_frame, probability = process_frame(frame, prev_frame)\n",
    "        prev_frame = frame.copy()\n",
    "        \n",
    "        total_probability += probability\n",
    "        frame_count += 1\n",
    "        \n",
    "        out.write(cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR))  # Save frame\n",
    "        \n",
    "        # Show frame\n",
    "        cv2.imshow(\"Processed Video\", processed_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    average_probability = total_probability // frame_count if frame_count else 0\n",
    "    generate_pdf(file_path, average_probability)\n",
    "    print(f\"Processed video saved as {output_path}\")\n",
    "\n",
    "def generate_pdf(file_name, confidence_score):\n",
    "    \"\"\" Generates a PDF report with confidence score. \"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=16)\n",
    "    pdf.cell(200, 10, \"Deepfake Detection Report\", ln=True, align='C')\n",
    "    pdf.ln(10)\n",
    "    \n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "    pdf.cell(200, 10, f\"File: {os.path.basename(file_name)}\", ln=True)\n",
    "    pdf.cell(200, 10, f\"Confidence Score: {confidence_score}%\", ln=True)\n",
    "    pdf.cell(200, 10, f\"Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\", ln=True)\n",
    "    \n",
    "    output_pdf = \"deepfake_report.pdf\"\n",
    "    pdf.output(output_pdf)\n",
    "    print(f\"Report saved as {output_pdf}\")\n",
    "\n",
    "# === MAIN MENU ===\n",
    "root = tk.Tk()\n",
    "root.title(\"Deepfake Detector\")\n",
    "root.geometry(\"400x300\")\n",
    "\n",
    "tk.Label(root, text=\"Choose an option:\", font=(\"Arial\", 14)).pack(pady=10)\n",
    "\n",
    "tk.Button(root, text=\"Process Image\", command=process_image, font=(\"Arial\", 12)).pack(pady=5)\n",
    "tk.Button(root, text=\"Process Video\", command=process_video, font=(\"Arial\", 12)).pack(pady=5)\n",
    "\n",
    "tk.Label(root, text=\"Processed files and PDF reports will be saved.\", font=(\"Arial\", 10)).pack(pady=10)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece80035-fa87-4e5e-92ba-3bea1ff5b4da",
   "metadata": {},
   "source": [
    "## FEATURE - 5 alert mechanism based on deepfake probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "901c3d72-3c6e-4379-a5c9-cd2b794acc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "from playsound import playsound\n",
    "\n",
    "# Load OpenCV's pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def detect_fake(frame, prev_frame):\n",
    "    \"\"\" Detects movement and calculates deepfake probability. \"\"\"\n",
    "    if prev_frame is None:\n",
    "        return 0  # No comparison possible\n",
    "\n",
    "    diff = cv2.absdiff(frame, prev_frame)\n",
    "    score = np.mean(diff)  # Calculate difference score\n",
    "\n",
    "    probability = min(int(score / 2), 100)  # Scale to 0-100%\n",
    "    return probability\n",
    "\n",
    "def process_frame(frame, prev_frame):\n",
    "    \"\"\" Detects faces and applies deepfake probability calculation. \"\"\"\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB for display\n",
    "    probability = detect_fake(frame, prev_frame)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        color = (255, 0, 0) if probability > 50 else (0, 255, 0)\n",
    "        cv2.rectangle(frame_rgb, (x, y), (x + w, y + h), color, 3)\n",
    "        cv2.putText(frame_rgb, f\"{probability}%\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        # Play alert sound if deepfake probability is high\n",
    "        if probability > 50:\n",
    "            playsound(\"alert.mp3\", block=False)\n",
    "\n",
    "    return frame_rgb, probability\n",
    "\n",
    "def open_webcam():\n",
    "    \"\"\" Opens webcam and performs real-time deepfake detection with sound alerts. \"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    prev_frame = None\n",
    "\n",
    "    def update_frame():\n",
    "        nonlocal prev_frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            return\n",
    "\n",
    "        frame, probability = process_frame(frame, prev_frame)\n",
    "        prev_frame = frame.copy()\n",
    "\n",
    "        img = Image.fromarray(frame)\n",
    "        img_tk = ImageTk.PhotoImage(image=img)\n",
    "        label.img_tk = img_tk\n",
    "        label.config(image=img_tk)\n",
    "\n",
    "        label_status.config(text=f\"Deepfake Probability: {probability}%\", fg=\"red\" if probability > 50 else \"green\")\n",
    "        root.after(10, update_frame)\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Deepfake Detector with Audio Alert\")\n",
    "\n",
    "    label = tk.Label(root)\n",
    "    label.pack()\n",
    "\n",
    "    label_status = tk.Label(root, text=\"\", font=(\"Arial\", 16, \"bold\"))\n",
    "    label_status.pack()\n",
    "\n",
    "    update_frame()\n",
    "    root.mainloop()\n",
    "    cap.release()\n",
    "\n",
    "# Run the webcam function\n",
    "open_webcam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70b17649-756f-4fd0-8062-6eef524fdc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import winsound  # Built-in module for beep sound (Windows only)\n",
    "\n",
    "def play_beep():\n",
    "    \"\"\"Plays a simple beep sound.\"\"\"\n",
    "    winsound.Beep(1000, 500)  # Frequency = 1000 Hz, Duration = 500 ms\n",
    "\n",
    "def open_image():\n",
    "    \"\"\"Opens a file dialog to select an image and displays it.\"\"\"\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpeg;*.jpg;*.png\")])\n",
    "    if not file_path:\n",
    "        return  # If no file is selected, do nothing\n",
    "\n",
    "    # Play beep sound\n",
    "    play_beep()\n",
    "\n",
    "    # Load image using OpenCV and convert it to RGB\n",
    "    image = cv2.imread(file_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert to Tkinter format and display\n",
    "    img = Image.fromarray(image)\n",
    "    img_tk = ImageTk.PhotoImage(img)\n",
    "\n",
    "    label.config(image=img_tk)\n",
    "    label.image = img_tk  # Keep reference to avoid garbage collection\n",
    "\n",
    "def exit_program(event):\n",
    "    \"\"\"Closes the application when 'q' is pressed.\"\"\"\n",
    "    root.quit()\n",
    "\n",
    "# Initialize Tkinter\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Upload with Beep Sound\")\n",
    "\n",
    "# Create GUI components\n",
    "btn_upload = tk.Button(root, text=\"Upload Image\", command=open_image, font=(\"Arial\", 14))\n",
    "btn_upload.pack(pady=10)\n",
    "\n",
    "label = tk.Label(root)\n",
    "label.pack()\n",
    "\n",
    "# Bind 'q' key to exit the application\n",
    "root.bind(\"<q>\", exit_program)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
